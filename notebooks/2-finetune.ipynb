{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f276c25c-cbee-4d9c-8338-98c5ed2ddb16",
   "metadata": {},
   "source": [
    "# Fine-tuning Setup for Llama Model\n",
    "\n",
    "## Environment Setup\n",
    "- Load environment variables\n",
    "- HuggingFace authentication setup\n",
    "- Load stored dataset paths\n",
    "- Initialize SageMaker session\n",
    "- Set up AWS role and bucket configuration\n",
    "- Configure region settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6461d952-6c5f-45ad-b9ed-cec4fcf89766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f9f27-d426-475a-892a-b4036c99bd5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_dotenv('../end.local')\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "if not HF_TOKEN:\n",
    "    raise ValueError(\"HF_TOKEN not found in environment variables\")\n",
    "\n",
    "!huggingface-cli login --token {HF_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "141a6a3c-2097-41f0-9c1d-a402f5abd8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r data_folder\n",
    "%store -r json_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e1d5a-867e-43d5-98da-5bd3c79873e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(data_folder)\n",
    "print(json_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe128b8-5438-4ec2-852f-f635c9316d75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    role = boto3.client('iam').get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session_bucket}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ab87f-b1a2-4e3c-84d5-7af8396c4ff0",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "- Create S3 paths for datasets\n",
    "- Upload training, validation and test datasets to S3\n",
    "- Create and upload model configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26308e-d753-4490-b146-0662833262aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create S3 paths\n",
    "DATASET_NAME = \"dolly_dataset\"\n",
    "s3_base_path = f's3://{sess.default_bucket()}/datasets/{DATASET_NAME}'\n",
    "\n",
    "s3_paths = {}\n",
    "for split_name, local_path in json_paths.items():\n",
    "    filename = os.path.basename(local_path)\n",
    "    s3_paths[split_name] = f\"{s3_base_path}/{split_name}/{filename}\"\n",
    "    print(f\"{split_name} dataset S3 path: {s3_paths[split_name]}\")\n",
    "\n",
    "    \n",
    "for split_name, local_path in json_paths.items():\n",
    "    try:\n",
    "        s3_prefix = os.path.dirname(s3_paths[split_name])\n",
    "        s3_path = S3Uploader.upload(\n",
    "            local_path=local_path,\n",
    "            desired_s3_uri=s3_prefix\n",
    "        )\n",
    "        print(f\"Successfully uploaded {local_path} to {s3_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading {split_name} dataset: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111976f9-3e9d-48f2-ba4c-b7dc06b19859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\nVerifying S3 uploads:\")\n",
    "!aws s3 ls {s3_base_path} --recursive --human-readable\n",
    "\n",
    "train_s3_path = s3_paths['train']\n",
    "validation_s3_path = s3_paths['validation']\n",
    "test_s3_path = s3_paths['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2516e907-6ece-4f0f-8132-c245262c81b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "config_folder_name = \"accelerator_config\"\n",
    "os.makedirs(config_folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c98458-f88c-421d-b3ef-8fcfadee46b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_content = \"\"\"\n",
    "# script parameters\n",
    "model_id: \"meta-llama/Llama-3.2-3B\"\n",
    "max_seq_length: 2048\n",
    "train_dataset_path: \"/opt/ml/input/data/train/\"\n",
    "validation_dataset_path: \"/opt/ml/input/data/validation/\"\n",
    "output_dir: \"/tmp/llama3\"\n",
    "\n",
    "# training parameters\n",
    "report_to: \"tensorboard\"\n",
    "learning_rate: 2e-4\n",
    "lr_scheduler_type: \"constant\"\n",
    "\n",
    "num_train_epochs: 3\n",
    "per_device_train_batch_size: 4\n",
    "per_device_eval_batch_size: 4\n",
    "gradient_accumulation_steps: 8\n",
    "\n",
    "optim: adamw_torch\n",
    "logging_steps: 10\n",
    "save_strategy: epoch\n",
    "eval_strategy: epoch\n",
    "max_grad_norm: 0.3\n",
    "warmup_ratio: 0.03\n",
    "bf16: true\n",
    "tf32: true\n",
    "gradient_checkpointing: true\n",
    "\"\"\"\n",
    "\n",
    "config_file_path = os.path.join(config_folder_name, \"sm_llama_3_2_3b_qlora.yaml\")\n",
    "with open(config_file_path, 'w') as f:\n",
    "    f.write(config_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f40ad-f901-4b53-b555-aadfe138d9c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ../scripts/requirements.txt\n",
    "\n",
    "datasets==3.0.0\n",
    "trl==0.11.1\n",
    "bitsandbytes==0.44.0\n",
    "peft==0.12.0\n",
    "accelerate==0.34.2\n",
    "sagemaker==2.232.1\n",
    "transformers==4.44.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec518e2-6fbc-4e6b-b36a-ec90b8cfc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"accelerator_config/sm_llama_3_2_3b_qlora.yaml\"\n",
    "config_s3_prefix = f\"{s3_base_path}/config\"\n",
    "\n",
    "# Upload config file to S3\n",
    "try:\n",
    "    train_config_s3_path = S3Uploader.upload(\n",
    "        local_path=CONFIG_FILE_PATH,\n",
    "        desired_s3_uri=config_s3_prefix\n",
    "    )\n",
    "    print(f\"\\nConfiguration file uploaded successfully to {train_config_s3_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading configuration: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014abafc-d599-448c-95e1-dc7de4f70328",
   "metadata": {},
   "source": [
    "## Training Configuration \n",
    "- Set up training instance configuration (ml.g5.4xlarge)\n",
    "- Configure metrics for monitoring\n",
    "- Set hyperparameters and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7d0c15d-14c8-4732-8546-314c1fd198d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_data = {\n",
    "    'train': train_s3_path,\n",
    "    'validation': validation_s3_path,\n",
    "    'config': train_config_s3_path\n",
    "}\n",
    "\n",
    "INSTANCE_CONFIG = {\n",
    "    'type': 'ml.g5.4xlarge',\n",
    "    'count': 1\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    'instance_type': INSTANCE_CONFIG['type'],\n",
    "    'instance_count': INSTANCE_CONFIG['count'],\n",
    "    'metric_definitions': [\n",
    "        {\"Name\": \"train:loss\", \"Regex\": \"'train_loss':(.*?),\"},\n",
    "        {\"Name\": \"validation:loss\", \"Regex\": \"'eval_loss':(.*?),\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee276081-df02-47a2-b7a6-58035d554713",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "import time\n",
    "\n",
    "# Training job configuration\n",
    "JOB_CONFIG = {\n",
    "    'entry_point': 'train.py',\n",
    "    'source_dir': '../scripts',\n",
    "    'max_run_seconds': 1*24*60*60,  # 1 day\n",
    "    'volume_size': 256,\n",
    "    'framework_version': {\n",
    "        'transformers': '4.36.0',\n",
    "        'pytorch': '2.1.0',\n",
    "        'python': 'py310'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate unique job name\n",
    "job_name = f'llama3-2-3b-finetune-{time.strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "\n",
    "\n",
    "# Initialize SageMaker estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=JOB_CONFIG['entry_point'],\n",
    "    source_dir=JOB_CONFIG['source_dir'],\n",
    "    instance_type=training_config['instance_type'],\n",
    "    instance_count=training_config['instance_count'],\n",
    "    sagemaker_session=sagemaker.session.Session(),\n",
    "    max_run=JOB_CONFIG['max_run_seconds'],\n",
    "    base_job_name=job_name,\n",
    "    role=role,\n",
    "    volume_size=JOB_CONFIG['volume_size'],\n",
    "    transformers_version=JOB_CONFIG['framework_version']['transformers'],\n",
    "    pytorch_version=JOB_CONFIG['framework_version']['pytorch'],\n",
    "    py_version=JOB_CONFIG['framework_version']['python'],\n",
    "    metric_definitions=training_config['metric_definitions'],\n",
    "    hyperparameters={\n",
    "        \"config\": \"/opt/ml/input/data/config/sm_llama_3_2_3b_qlora.yaml\"\n",
    "    },\n",
    "    disable_output_compression=True,\n",
    "    keep_alive_period_in_seconds=3600,\n",
    "    distribution={\"torch_distributed\": {\"enabled\": False}},\n",
    "    environment={\n",
    "        \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\",\n",
    "        \"HF_TOKEN\": HF_TOKEN\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192e0fb-3f8e-420c-b92b-bbf115471277",
   "metadata": {},
   "source": [
    "## Training Job Launch\n",
    "- Initialize HuggingFace estimator\n",
    "- Configure training job settings\n",
    "- Launch training experiment\n",
    "- Monitor training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a26b55-fd3b-4d34-be54-9a708010ff39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.experiments.run import Run\n",
    "\n",
    "# Initialize SageMaker experiment\n",
    "experiment_config = {\n",
    "    'name': 'dolly-ft',\n",
    "    'run_name': f'training-job-experiment-{time.strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "}\n",
    "\n",
    "# Start experiment and training\n",
    "with Run(\n",
    "    experiment_name=experiment_config['name'], \n",
    "    run_name=experiment_config['run_name'], \n",
    "    sagemaker_session=sagemaker.session.Session()\n",
    ") as run:\n",
    "    huggingface_estimator.fit(s3_data, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faacb6c0-1533-4018-8dcb-f65d07c6cd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8e3c1-c947-4d53-89dd-6039050d512f",
   "metadata": {},
   "source": [
    "## Model Artifacts\n",
    "- Store model S3 path for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99feb1-5d64-458d-b5f3-8331df430399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_path = huggingface_estimator.model_data\n",
    "print(\"model_s3_path: \\n\", model_s3_path)\n",
    "\n",
    "%store model_s3_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3-env",
   "language": "python",
   "name": "llama3-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
